## GPTQ-for-LLaMa
Cuda: 11.8 & 12.1

Python 3.10.9 & 3.11.3

https://github.com/qwopqwop200/GPTQ-for-LLaMa -b cuda

https://github.com/oobabooga/GPTQ-for-LLaMa.git -b cuda




## xformers

Cuda: 11.8 & 12.1

Python 3.11.3



## bitsandbytres

Cuda: 11.8 & 12.1

Python 3.11.3
